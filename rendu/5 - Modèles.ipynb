{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie on va essayer d'utiliser des modèles d'apprentissage machine pour prédire les scores des joueurs. On commence par récupérer le dataset et le mettre en forme pour l'apprentissage.\n",
    "\n",
    "Les choix que l'on fait sont les suivants :\n",
    "  - On ne garde pas les variables qui dépendent du match :\n",
    "      - list_var_avg + WIN\n",
    "  - On ne garde pas les variables qui nous donne aucune information : \n",
    "      - SEASON_ID, GAME_ID\n",
    "  - On modifie le type de la variable PLAYER_ID pour pas qu'elle soit considérée comme un nombre\n",
    "  - On ne garde pas les variables agrégées sur les équipes car elles sont trop souvent `Nan` car les équipes ne se jouent pas souvent (4 fois max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La liste des variables dont on va récupérer les moyennes\n",
    "list_var_avg = ['PTS', 'REB', 'AST', 'STL', 'BLK', 'FGM', 'FTM', 'FG3M',\n",
    "                 'TOV', 'FGF', 'FG3F', 'FTF', 'BONUS', 'MALUS', 'SCORE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupere le dataset\n",
    "df = pd.read_csv('../data/boxscore_2019_final.csv')\n",
    "\n",
    "df = df.drop(list_var_avg[:-1]+['WIN', 'SEASON_ID', 'GAME_ID'], axis=1)\n",
    "df = df[~df.AVG_SCORE.isna()]\n",
    "\n",
    "df.PLAYER_ID = df.PLAYER_ID.astype(object)\n",
    "\n",
    "# Pour l'instant on retire aussi les variables de moyenne par équipe car elles \n",
    "# sont trop souvant vide\n",
    "df = df.drop(['AVG_ADD_'+x for x in list_var_avg]+['AVG_BONUS', 'AVG_MALUS', 'AVG_SCORE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>ADV</th>\n",
       "      <th>HOME</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>AVG_PTS</th>\n",
       "      <th>AVG_REB</th>\n",
       "      <th>AVG_AST</th>\n",
       "      <th>AVG_STL</th>\n",
       "      <th>AVG_BLK</th>\n",
       "      <th>AVG_FGM</th>\n",
       "      <th>AVG_FTM</th>\n",
       "      <th>AVG_FG3M</th>\n",
       "      <th>AVG_TOV</th>\n",
       "      <th>AVG_FGF</th>\n",
       "      <th>AVG_FG3F</th>\n",
       "      <th>AVG_FTF</th>\n",
       "      <th>NB_VIC</th>\n",
       "      <th>NB_VIC_ADD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>201580</td>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>LAL</td>\n",
       "      <td>MEM</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12716</th>\n",
       "      <td>1626209</td>\n",
       "      <td>2020-08-13</td>\n",
       "      <td>POR</td>\n",
       "      <td>BKN</td>\n",
       "      <td>False</td>\n",
       "      <td>-3</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>201599</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>BKN</td>\n",
       "      <td>BOS</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PLAYER_ID   GAME_DATE TEAM  ADV   HOME  SCORE   AVG_PTS    AVG_REB  \\\n",
       "2399     201580  2019-10-29  LAL  MEM   True     21  4.666667   3.333333   \n",
       "12716   1626209  2020-08-13  POR  BKN  False     -3  6.333333   5.000000   \n",
       "2712     201599  2020-03-03  BKN  BOS  False     27  9.333333  11.000000   \n",
       "\n",
       "        AVG_AST   AVG_STL   AVG_BLK   AVG_FGM  AVG_FTM  AVG_FG3M   AVG_TOV  \\\n",
       "2399   0.333333  0.333333  0.666667  2.333333      0.0  0.000000  1.333333   \n",
       "12716  2.000000  1.000000  0.000000  2.333333      1.0  0.666667  0.333333   \n",
       "2712   1.333333  0.000000  0.666667  3.666667      2.0  0.000000  0.666667   \n",
       "\n",
       "        AVG_FGF  AVG_FG3F   AVG_FTF  NB_VIC  NB_VIC_ADD  \n",
       "2399   1.666667  0.000000  0.333333       2           0  \n",
       "12716  3.333333  2.333333  0.333333       2           0  \n",
       "2712   1.333333  0.000000  1.333333       0           1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Séparation de la base\n",
    "\n",
    "Pour pouvoir évaluer les différents modèles que nous allons utiliser Sélim nous a conseiller de faire une *K-fold cross validation* qui très grossièrement consiste à tester son modèles sur différentes partie du data set pour mesurer sa robustesse.\n",
    "\n",
    "Dans le cas de données temporelles on ne peut pas simplement prendre des parties aléatoires car on risquerait d'avoir des données du futur dans notre base d'entrainement et des données du passé dans celle de test. On se base sur cet [article](https://medium.com/@soumyachess1496/cross-validation-in-time-series-566ae4981ce4) pour les différentes méthodes de *cross-validation* dans des séries temporelles.\n",
    "\n",
    "Les deux méthodes simples que l'on retient sont :\n",
    "  - *Time Series Split Cross-Validation*\n",
    "  - *Blocked Cross-Validation*\n",
    "\n",
    "IMAGE 1 // IMAGE 2\n",
    "\n",
    "La deuxième est utilisé lorsque l'on suspecte que connaitre des données futurs peut permetre de prédire plus précisément des données passées. Comme nous partons du principe que la probabilité de faire un bon score ne dépend que du passé et jamais du futur nous avons décidé d'implémenter la méthode *Time Serie Split Cross-Validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le nombre de cross validation+1 que l'on veut\n",
    "K=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIZE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPLIT</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SIZE\n",
       "SPLIT      \n",
       "0      4358\n",
       "1      4775\n",
       "2      4653\n",
       "3      4644\n",
       "4      3211\n",
       "5       853"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On transforme les variables catégorielles en encodage oneshot\n",
    "df = pd.get_dummies(df, columns=['PLAYER_ID', 'TEAM', 'ADV'])\n",
    "\n",
    "# On récupère les dates pour les séparer en K parties\n",
    "dates = df.GAME_DATE.sort_values().unique()\n",
    "\n",
    "# On crée les critères de séléction la base\n",
    "criteres = [df.GAME_DATE.between(x[0], x[-1]) for x in np.array_split(dates, K)]\n",
    "valeurs = range(K)\n",
    "\n",
    "# On créé la variable de découpe\n",
    "df = df.assign(SPLIT=np.select(criteres, valeurs, df.GAME_DATE))\n",
    "\n",
    "# On créé les dataframes\n",
    "df.groupby('SPLIT').size().to_frame(name='SIZE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que la dernière partie ne contient que très peu d'entrées. On l'explique par le fait que l'on a séparer les groupes en se basant sur les dates et non sur le nombre de match entre deux dates. À la fin de la saison on se retrouve avec les playoff donc il y a beaucoup moins de match. Pour équilibrer on va concatener les deux dernières parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_df = []\n",
    "\n",
    "for _, df_split in df.drop('GAME_DATE', axis=1).groupby('SPLIT'):\n",
    "    lst_df += [df_split]\n",
    "\n",
    "last_df = lst_df.pop()\n",
    "lst_df[-1] = pd.concat([lst_df[-1], last_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4358, 4775, 4653, 4644, 4064]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in lst_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se retrouve donc avec K-1 bases de données assez équilibrées sur lesquelles on peut tester les modèles de machines learnings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Modèles linéaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne garde que les joueurs qui ont joué plus de 50 matchs sur la saison\n",
    "df_players = (df.groupby('PLAYER_ID').count() > 50)\n",
    "list_players = df_players[df_players.SCORE].index\n",
    "df = df[df.PLAYER_ID.isin(list_players)].reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
